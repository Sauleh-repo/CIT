{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbdONbYimxLh"
      },
      "source": [
        "# Image classification with Vision Transformer\n",
        "\n",
        "**Author:** [Khalid Salama](https://www.linkedin.com/in/khalid-salama-24403144/)<br>\n",
        "**Date created:** 2021/01/18<br>\n",
        "**Last modified:** 2021/01/18<br>\n",
        "**Description:** Implementing the Vision Transformer (ViT) model for image classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LttEyzg7mxL5"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "This example implements the [Vision Transformer (ViT)](https://arxiv.org/abs/2010.11929)\n",
        "model by Alexey Dosovitskiy et al. for image classification,\n",
        "and demonstrates it on the CIFAR-100 dataset.\n",
        "The ViT model applies the Transformer architecture with self-attention to sequences of\n",
        "image patches, without using convolution layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Xa8LE2PmxL8"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "MoxIqE-NmxL-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # @param [\"tensorflow\", \"jax\", \"torch\"]\n",
        "\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras import ops\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IbAGuzEmxME"
      },
      "source": [
        "## Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "no5zBeg7mxMG",
        "outputId": "edafc3c9-d731-45d9-c73f-c866816af9d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (50000, 32, 32, 3) - y_train shape: (50000, 1)\n",
            "x_test shape: (10000, 32, 32, 3) - y_test shape: (10000, 1)\n"
          ]
        }
      ],
      "source": [
        "num_classes = 100\n",
        "input_shape = (32, 32, 3)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()\n",
        "\n",
        "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
        "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v51HAIzpmxMH"
      },
      "source": [
        "## Configure the hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "hVgxVvovmxMJ"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "weight_decay = 0.0001\n",
        "batch_size = 256\n",
        "num_epochs = 10  # For real training, use num_epochs=100. 10 is a test value\n",
        "image_size = 72  # We'll resize input images to this size\n",
        "patch_size = 6  # Size of the patches to be extract from the input images\n",
        "num_patches = (image_size // patch_size) ** 2\n",
        "projection_dim = 64\n",
        "num_heads = 4\n",
        "transformer_units = [\n",
        "    projection_dim * 2,\n",
        "    projection_dim,\n",
        "]  # Size of the transformer layers\n",
        "transformer_layers = 8\n",
        "mlp_head_units = [\n",
        "    2048,\n",
        "    1024,\n",
        "]  # Size of the dense layers of the final classifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9tLMeQ5mxML"
      },
      "source": [
        "## Use data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "Y4cFxBU6mxMM"
      },
      "outputs": [],
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.Normalization(),\n",
        "        layers.Resizing(image_size, image_size),\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(factor=0.02),\n",
        "        layers.RandomZoom(height_factor=0.2, width_factor=0.2),\n",
        "    ],\n",
        "    name=\"data_augmentation\",\n",
        ")\n",
        "# Compute the mean and the variance of the training data for normalization.\n",
        "data_augmentation.layers[0].adapt(x_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MIALKQemxMO"
      },
      "source": [
        "## Implement multilayer perceptron (MLP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "k-wsiNhsmxMQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "def mlp(x, hidden_units, dropout_rate):\n",
        "    for units in hidden_units:\n",
        "        x = layers.Dense(units, activation=keras.activations.gelu)(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUPv1M39mxMR"
      },
      "source": [
        "## Implement patch creation as a layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "JDRBwqiZmxMS"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Patches(layers.Layer):\n",
        "    def __init__(self, patch_size):\n",
        "        super().__init__()\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "    def call(self, images):\n",
        "        input_shape = ops.shape(images)\n",
        "        batch_size = input_shape[0]\n",
        "        height = input_shape[1]\n",
        "        width = input_shape[2]\n",
        "        channels = input_shape[3]\n",
        "        num_patches_h = height // self.patch_size\n",
        "        num_patches_w = width // self.patch_size\n",
        "        patches = keras.ops.image.extract_patches(images, size=self.patch_size)\n",
        "        patches = ops.reshape(\n",
        "            patches,\n",
        "            (\n",
        "                batch_size,\n",
        "                num_patches_h * num_patches_w,\n",
        "                self.patch_size * self.patch_size * channels,\n",
        "            ),\n",
        "        )\n",
        "        return patches\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\"patch_size\": self.patch_size})\n",
        "        return config\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wltfnTVmxMU"
      },
      "source": [
        "Let's display patches for a sample image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "RQdxyw4lmxMU",
        "outputId": "e62f9cac-a420-4002-a993-34aa7b213fba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image size: 72 X 72\n",
            "Patch size: 6 X 6\n",
            "Patches per image: 144\n",
            "Elements per patch: 108\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 144 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(4, 4))\n",
        "image = x_train[np.random.choice(range(x_train.shape[0]))]\n",
        "plt.imshow(image.astype(\"uint8\"))\n",
        "plt.axis(\"off\")\n",
        "\n",
        "resized_image = ops.image.resize(\n",
        "    ops.convert_to_tensor([image]), size=(image_size, image_size)\n",
        ")\n",
        "patches = Patches(patch_size)(resized_image)\n",
        "print(f\"Image size: {image_size} X {image_size}\")\n",
        "print(f\"Patch size: {patch_size} X {patch_size}\")\n",
        "print(f\"Patches per image: {patches.shape[1]}\")\n",
        "print(f\"Elements per patch: {patches.shape[-1]}\")\n",
        "\n",
        "n = int(np.sqrt(patches.shape[1]))\n",
        "plt.figure(figsize=(4, 4))\n",
        "for i, patch in enumerate(patches[0]):\n",
        "    ax = plt.subplot(n, n, i + 1)\n",
        "    patch_img = ops.reshape(patch, (patch_size, patch_size, 3))\n",
        "    plt.imshow(ops.convert_to_numpy(patch_img).astype(\"uint8\"))\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7g2bGK7mxMV"
      },
      "source": [
        "## Implement the patch encoding layer\n",
        "\n",
        "The `PatchEncoder` layer will linearly transform a patch by projecting it into a\n",
        "vector of size `projection_dim`. In addition, it adds a learnable position\n",
        "embedding to the projected vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "VrLdupSKmxMW"
      },
      "outputs": [],
      "source": [
        "\n",
        "class PatchEncoder(layers.Layer):\n",
        "    def __init__(self, num_patches, projection_dim):\n",
        "        super().__init__()\n",
        "        self.num_patches = num_patches\n",
        "        self.projection = layers.Dense(units=projection_dim)\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=projection_dim\n",
        "        )\n",
        "\n",
        "    def call(self, patch):\n",
        "        positions = ops.expand_dims(\n",
        "            ops.arange(start=0, stop=self.num_patches, step=1), axis=0\n",
        "        )\n",
        "        projected_patches = self.projection(patch)\n",
        "        encoded = projected_patches + self.position_embedding(positions)\n",
        "        return encoded\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\"num_patches\": self.num_patches})\n",
        "        return config\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1_hJ8FomxMX"
      },
      "source": [
        "## Build the ViT model\n",
        "\n",
        "The ViT model consists of multiple Transformer blocks,\n",
        "which use the `layers.MultiHeadAttention` layer as a self-attention mechanism\n",
        "applied to the sequence of patches. The Transformer blocks produce a\n",
        "`[batch_size, num_patches, projection_dim]` tensor, which is processed via an\n",
        "classifier head with softmax to produce the final class probabilities output.\n",
        "\n",
        "Unlike the technique described in the [paper](https://arxiv.org/abs/2010.11929),\n",
        "which prepends a learnable embedding to the sequence of encoded patches to serve\n",
        "as the image representation, all the outputs of the final Transformer block are\n",
        "reshaped with `layers.Flatten()` and used as the image\n",
        "representation input to the classifier head.\n",
        "Note that the `layers.GlobalAveragePooling1D` layer\n",
        "could also be used instead to aggregate the outputs of the Transformer block,\n",
        "especially when the number of patches and the projection dimensions are large."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "Wl0ycwEHmxMY"
      },
      "outputs": [],
      "source": [
        "\n",
        "def create_vit_classifier():\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    # Augment data.\n",
        "    augmented = data_augmentation(inputs)\n",
        "    # Create patches.\n",
        "    patches = Patches(patch_size)(augmented)\n",
        "    # Encode patches.\n",
        "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
        "\n",
        "    # Create multiple layers of the Transformer block.\n",
        "    for _ in range(transformer_layers):\n",
        "        # Layer normalization 1.\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "        # Create a multi-head attention layer.\n",
        "        attention_output = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
        "        )(x1, x1)\n",
        "        # Skip connection 1.\n",
        "        x2 = layers.Add()([attention_output, encoded_patches])\n",
        "        # Layer normalization 2.\n",
        "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "        # MLP.\n",
        "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
        "        # Skip connection 2.\n",
        "        encoded_patches = layers.Add()([x3, x2])\n",
        "\n",
        "    # Create a [batch_size, projection_dim] tensor.\n",
        "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "    representation = layers.Flatten()(representation)\n",
        "    representation = layers.Dropout(0.5)(representation)\n",
        "    # Add MLP.\n",
        "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
        "    # Classify outputs.\n",
        "    logits = layers.Dense(num_classes)(features)\n",
        "    # Create the Keras model.\n",
        "    model = keras.Model(inputs=inputs, outputs=logits)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbT-H4vXmxMa"
      },
      "source": [
        "## Compile, train, and evaluate the mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "rJJRNc-UmxMb",
        "outputId": "cfe4574d-1781-4b5f-a875-695556755f39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m  9/176\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:29\u001b[0m 2s/step - accuracy: 0.0083 - loss: 6.8449 - top-5-accuracy: 0.0622"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-e119019e2da8>\u001b[0m in \u001b[0;36m<cell line: 41>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mvit_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_vit_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvit_classifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-57-e119019e2da8>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     21\u001b[0m     )\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     history = model.fit(\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/jax/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    421\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jax_state_synced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m                 \u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m                 (\n\u001b[1;32m    425\u001b[0m                     \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/jax/trainer.py\u001b[0m in \u001b[0;36mone_train_step\u001b[0;34m(state, data)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mone_train_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mmulti_train_steps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/jax/trainer.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, state, data)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_and_updates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         )\n\u001b[0;32m---> 99\u001b[0;31m         (loss, aux), grads = grad_fn(\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mnon_trainable_variables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36mvalue_and_grad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    703\u001b[0m       \u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvjp_py\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_vjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_partial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mdyn_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m       ans, vjp_py, aux = _vjp(\n\u001b[0m\u001b[1;32m    706\u001b[0m           f_partial, *dyn_args, has_aux=True)\n\u001b[1;32m    707\u001b[0m     \u001b[0m_check_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36m_vjp\u001b[0;34m(fun, has_aux, *primals)\u001b[0m\n\u001b[1;32m   2199\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2200\u001b[0m     \u001b[0mflat_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_aux_trees\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_fun_nokwargs2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2201\u001b[0;31m     \u001b[0mout_primals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimals_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2202\u001b[0m     \u001b[0mout_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_aux_trees\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2203\u001b[0m   \u001b[0mout_primal_avals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshaped_abstractify\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_primals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/interpreters/ad.py\u001b[0m in \u001b[0;36mvjp\u001b[0;34m(traceable, primals, has_aux)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0mout_primals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinearize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mprimals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m     \u001b[0mout_primals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinearize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mprimals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0munbound_vjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mcts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/interpreters/ad.py\u001b[0m in \u001b[0;36mlinearize\u001b[0;34m(traceable, *primals, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m   \u001b[0mjvpfun_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjvpfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m   \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_pvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_to_jaxpr_nounits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjvpfun_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_pvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m   \u001b[0mout_primals_pvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tangents_pvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_pvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m   \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_primal_pval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_known\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mout_primal_pval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mout_primals_pvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/profiler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mTraceAnnotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdecorator_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/interpreters/partial_eval.py\u001b[0m in \u001b[0;36mtrace_to_jaxpr_nounits\u001b[0;34m(fun, pvals, instantiate)\u001b[0m\n\u001b[1;32m    776\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJaxprTrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_stack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurrent_name_stack\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[0mfun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_to_subjaxpr_nounits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstantiate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m     \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout_pvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/linear_util.py\u001b[0m in \u001b[0;36mcall_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m       \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m       \u001b[0;31m# Some transformations yield from inside context managers, so we have to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/jax/trainer.py\u001b[0m in \u001b[0;36mcompute_loss_and_updates\u001b[0;34m(self, trainable_variables, non_trainable_variables, metrics_variables, x, y, sample_weight, training, optimizer_variables)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# Run stateless forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         y_pred, non_trainable_variables, losses = self.stateless_call(\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mnon_trainable_variables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36mstateless_call\u001b[0;34m(self, trainable_variables, non_trainable_variables, return_losses, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1039\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantized_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreturn_losses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m                 \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                     \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         outputs = self._run_through_graph(\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moperation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/ops/function.py\u001b[0m in \u001b[0;36m_run_through_graph\u001b[0;34m(self, inputs, operation_fn, call_fn)\u001b[0m\n\u001b[1;32m    169\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    558\u001b[0m         ):\n\u001b[1;32m    559\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"training\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    899\u001b[0m                         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;31m# Change the layout for the layer output if needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# This is useful for relayout intermediate tensor in the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mobject_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.__class__.__name__}.call()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             )\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# Plain flow.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/ops/numpy.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m   3443\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many_symbolic_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3444\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mMatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3445\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/jax/numpy.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m    119\u001b[0m         )\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreferred_element_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreferred_element_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/pjit.py\u001b[0m in \u001b[0;36mcache_miss\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0mexecutable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_most_recent_pjit_call_executable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjaxpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0mpgle_profiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_pgle_profiler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjaxpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m     maybe_fastpath_data = _get_fastpath_data(\n\u001b[0m\u001b[1;32m    337\u001b[0m         \u001b[0mexecutable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs_tracked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mjaxpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjit_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstracted_axes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/pjit.py\u001b[0m in \u001b[0;36m_get_fastpath_data\u001b[0;34m(executable, out_tree, args_flat, out_flat, attrs_tracked, effects, consts, abstracted_axes, pgle_profiler)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0mconsts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabstracted_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpgle_profiler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m ) -> pxla.MeshExecutableFastpathData | None:\n\u001b[0;32m--> 248\u001b[0;31m   \u001b[0mout_reflattened\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpxla\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreflatten_outputs_for_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m   use_fastpath = (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "def run_experiment(model):\n",
        "    optimizer = keras.optimizers.AdamW(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[\n",
        "            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
        "            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    checkpoint_filepath = \"/tmp/checkpoint.weights.h5\"\n",
        "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "        checkpoint_filepath,\n",
        "        monitor=\"val_accuracy\",\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True,\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        x=x_train,\n",
        "        y=y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=num_epochs,\n",
        "        validation_split=0.1,\n",
        "        callbacks=[checkpoint_callback],\n",
        "    )\n",
        "\n",
        "    model.load_weights(checkpoint_filepath)\n",
        "    _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
        "\n",
        "    return history\n",
        "\n",
        "\n",
        "vit_classifier = create_vit_classifier()\n",
        "history = run_experiment(vit_classifier)\n",
        "\n",
        "\n",
        "def plot_history(item):\n",
        "    plt.plot(history.history[item], label=item)\n",
        "    plt.plot(history.history[\"val_\" + item], label=\"val_\" + item)\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(item)\n",
        "    plt.title(\"Train and Validation {} Over Epochs\".format(item), fontsize=14)\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_history(\"loss\")\n",
        "plot_history(\"top-5-accuracy\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eq-xZs2mxMc"
      },
      "source": [
        "After 100 epochs, the ViT model achieves around 55% accuracy and\n",
        "82% top-5 accuracy on the test data. These are not competitive results on the CIFAR-100 dataset,\n",
        "as a ResNet50V2 trained from scratch on the same data can achieve 67% accuracy.\n",
        "\n",
        "Note that the state of the art results reported in the\n",
        "[paper](https://arxiv.org/abs/2010.11929) are achieved by pre-training the ViT model using\n",
        "the JFT-300M dataset, then fine-tuning it on the target dataset. To improve the model quality\n",
        "without pre-training, you can try to train the model for more epochs, use a larger number of\n",
        "Transformer layers, resize the input images, change the patch size, or increase the projection dimensions.\n",
        "Besides, as mentioned in the paper, the quality of the model is affected not only by architecture choices,\n",
        "but also by parameters such as the learning rate schedule, optimizer, weight decay, etc.\n",
        "In practice, it's recommended to fine-tune a ViT model\n",
        "that was pre-trained using a large, high-resolution dataset."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "image_classification_with_vision_transformer",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}